{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqXHB8N-boJc"
      },
      "source": [
        "<p align=\"center\"><b><font size=\"6\"> Macine Learning in practice</b></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.1)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.51.3)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
            "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (3.5.1)\n",
            "Requirement already satisfied: imblearn in ./.venv/lib/python3.12/site-packages (0.0)\n",
            "Requirement already satisfied: tensorflow in ./.venv/lib/python3.12/site-packages (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.3.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from datasets) (3.11.18)\n",
            "Requirement already satisfied: imbalanced-learn in ./.venv/lib/python3.12/site-packages (from imblearn) (0.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.12/site-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in ./.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in ./.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install pandas numpy matplotlib transformers torch datasets imblearn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexandresani/Library/CloudStorage/OneDrive-Personnel/Scolaire/Columbia/Spring 2025/ML in practice/PROJECT/ML in practice Github/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "random_seed = 42\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "labelling_budgets=[16, 32, 64, 128, 256, 512, 1024]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZgBX35yYDL-"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wK2x3CMpov7i",
        "outputId": "5b728e92-d0ba-448e-e766-9a38535e3804"
      },
      "outputs": [],
      "source": [
        "# IMDB Movie Reviews\n",
        "train_path = \"Raw Data/IMDB Movie Reviews/train_dataset.csv\"\n",
        "test_path = \"Raw Data/IMDB Movie Reviews/test_dataset.csv\"\n",
        "unsupervised_path = \"Raw Data/IMDB Movie Reviews/unsupervised_dataset.csv\"\n",
        "\n",
        "IMDB_train = pd.read_csv(train_path)\n",
        "IMDB_test = pd.read_csv(test_path)\n",
        "IMDB_unsupervised = pd.read_csv(unsupervised_path)\n",
        "\n",
        "\n",
        "#Wikipedia Comments\n",
        "wiki_comments_path = \"Raw Data/Wikipedia Personal Attacks/attack_annotated_comments.tsv\"\n",
        "wiki_annotations_path = \"Raw Data/Wikipedia Personal Attacks/attack_annotations.tsv\"\n",
        "wiki_keywords_path = \"Raw Data/Wikipedia Personal Attacks/keywords.csv\"\n",
        "\n",
        "wiki_comments = pd.read_csv(wiki_comments_path, sep='\\t')\n",
        "wiki_annotations = pd.read_csv(wiki_annotations_path, sep='\\t')\n",
        "keywords = pd.read_csv(wiki_keywords_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rev_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>year</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>ns</th>\n",
              "      <th>sample</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37675</td>\n",
              "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44816</td>\n",
              "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49851</td>\n",
              "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>89320</td>\n",
              "      <td>Next, maybe you could work on being less cond...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>93890</td>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115859</th>\n",
              "      <td>699848324</td>\n",
              "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>blocked</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115860</th>\n",
              "      <td>699851288</td>\n",
              "      <td>NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>blocked</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115861</th>\n",
              "      <td>699857133</td>\n",
              "      <td>NEWLINE_TOKEN:The way you're trying to describ...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>blocked</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115862</th>\n",
              "      <td>699891012</td>\n",
              "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>user</td>\n",
              "      <td>blocked</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115863</th>\n",
              "      <td>699897151</td>\n",
              "      <td>Alternate option===NEWLINE_TOKENIs there perha...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>blocked</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>115864 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           rev_id                                            comment  year  \\\n",
              "0           37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002   \n",
              "1           44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002   \n",
              "2           49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002   \n",
              "3           89320   Next, maybe you could work on being less cond...  2002   \n",
              "4           93890               This page will need disambiguation.   2002   \n",
              "...           ...                                                ...   ...   \n",
              "115859  699848324  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...  2016   \n",
              "115860  699851288  NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...  2016   \n",
              "115861  699857133  NEWLINE_TOKEN:The way you're trying to describ...  2016   \n",
              "115862  699891012  NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...  2016   \n",
              "115863  699897151  Alternate option===NEWLINE_TOKENIs there perha...  2016   \n",
              "\n",
              "        logged_in       ns   sample  split  \n",
              "0           False  article   random  train  \n",
              "1           False  article   random  train  \n",
              "2           False  article   random  train  \n",
              "3            True  article   random    dev  \n",
              "4            True  article   random  train  \n",
              "...           ...      ...      ...    ...  \n",
              "115859       True  article  blocked  train  \n",
              "115860       True  article  blocked   test  \n",
              "115861       True  article  blocked  train  \n",
              "115862       True     user  blocked    dev  \n",
              "115863       True  article  blocked  train  \n",
              "\n",
              "[115864 rows x 7 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rev_id</th>\n",
              "      <th>worker_id</th>\n",
              "      <th>quoting_attack</th>\n",
              "      <th>recipient_attack</th>\n",
              "      <th>third_party_attack</th>\n",
              "      <th>other_attack</th>\n",
              "      <th>attack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37675</td>\n",
              "      <td>1362</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37675</td>\n",
              "      <td>2408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37675</td>\n",
              "      <td>1493</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37675</td>\n",
              "      <td>1439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37675</td>\n",
              "      <td>170</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365212</th>\n",
              "      <td>699897151</td>\n",
              "      <td>628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365213</th>\n",
              "      <td>699897151</td>\n",
              "      <td>15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365214</th>\n",
              "      <td>699897151</td>\n",
              "      <td>57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365215</th>\n",
              "      <td>699897151</td>\n",
              "      <td>1815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365216</th>\n",
              "      <td>699897151</td>\n",
              "      <td>472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1365217 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            rev_id  worker_id  quoting_attack  recipient_attack  \\\n",
              "0            37675       1362             0.0               0.0   \n",
              "1            37675       2408             0.0               0.0   \n",
              "2            37675       1493             0.0               0.0   \n",
              "3            37675       1439             0.0               0.0   \n",
              "4            37675        170             0.0               0.0   \n",
              "...            ...        ...             ...               ...   \n",
              "1365212  699897151        628             0.0               0.0   \n",
              "1365213  699897151         15             0.0               0.0   \n",
              "1365214  699897151         57             0.0               0.0   \n",
              "1365215  699897151       1815             0.0               0.0   \n",
              "1365216  699897151        472             0.0               0.0   \n",
              "\n",
              "         third_party_attack  other_attack  attack  \n",
              "0                       0.0           0.0     0.0  \n",
              "1                       0.0           0.0     0.0  \n",
              "2                       0.0           0.0     0.0  \n",
              "3                       0.0           0.0     0.0  \n",
              "4                       0.0           0.0     0.0  \n",
              "...                     ...           ...     ...  \n",
              "1365212                 0.0           0.0     0.0  \n",
              "1365213                 0.0           0.0     0.0  \n",
              "1365214                 0.0           0.0     0.0  \n",
              "1365215                 0.0           0.0     0.0  \n",
              "1365216                 0.0           0.0     0.0  \n",
              "\n",
              "[1365217 rows x 7 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cols = ['rev_id', 'worker_id', 'attack']\n",
        "# wiki_data = wiki_annotations[cols].copy()\n",
        "# wiki_data['comment'] = wiki_data['rev_id'].apply(lambda x: wiki_comments[wiki_comments['rev_id']==x]['comment'].values[0])\n",
        "\n",
        "# wiki_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rev_id</th>\n",
              "      <th>text</th>\n",
              "      <th>split</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37675</td>\n",
              "      <td>`-This is not ``creative``.  Those are the dic...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44816</td>\n",
              "      <td>`:: the term ``standard model`` is itself less...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49851</td>\n",
              "      <td>True or false, the situation as of March 2002 ...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>89320</td>\n",
              "      <td>Next, maybe you could work on being less cond...</td>\n",
              "      <td>dev</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>93890</td>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115859</th>\n",
              "      <td>699848324</td>\n",
              "      <td>`These sources don't exactly exude a sense of ...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115860</th>\n",
              "      <td>699851288</td>\n",
              "      <td>The Institute for Historical Review is a peer-...</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115861</th>\n",
              "      <td>699857133</td>\n",
              "      <td>:The way you're trying to describe it in this ...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115862</th>\n",
              "      <td>699891012</td>\n",
              "      <td>== Warning ==There is clearly a protectionist ...</td>\n",
              "      <td>dev</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115863</th>\n",
              "      <td>699897151</td>\n",
              "      <td>Alternate option===Is there perhaps enough new...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>115864 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           rev_id                                               text  split  \\\n",
              "0           37675  `-This is not ``creative``.  Those are the dic...  train   \n",
              "1           44816  `:: the term ``standard model`` is itself less...  train   \n",
              "2           49851  True or false, the situation as of March 2002 ...  train   \n",
              "3           89320   Next, maybe you could work on being less cond...    dev   \n",
              "4           93890               This page will need disambiguation.   train   \n",
              "...           ...                                                ...    ...   \n",
              "115859  699848324  `These sources don't exactly exude a sense of ...  train   \n",
              "115860  699851288  The Institute for Historical Review is a peer-...   test   \n",
              "115861  699857133  :The way you're trying to describe it in this ...  train   \n",
              "115862  699891012  == Warning ==There is clearly a protectionist ...    dev   \n",
              "115863  699897151  Alternate option===Is there perhaps enough new...  train   \n",
              "\n",
              "        label  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "115859      0  \n",
              "115860      0  \n",
              "115861      0  \n",
              "115862      0  \n",
              "115863      0  \n",
              "\n",
              "[115864 rows x 4 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cols = ['rev_id', 'comment', 'split']\n",
        "wiki_data = wiki_comments[cols].copy()\n",
        "wiki_data['label'] = wiki_data['rev_id'].map(\n",
        "    wiki_annotations.groupby('rev_id')['attack'].mean().round().astype(int)\n",
        ")\n",
        "wiki_data[\"comment\"] = wiki_data[\"comment\"].str.replace(\"NEWLINE_TOKEN\", \"\")\n",
        "wiki_data = wiki_data.rename(columns={\"comment\": \"text\"})\n",
        "wiki_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wiki_data[\"comment\"] = wiki_data[\"comment\"].str.replace(\"NEWLINE_TOKEN\", \"\")\n",
        "# wiki_data = wiki_data.drop(columns=[\"ns\", \"sample\", \"year\"])\n",
        "# wiki_data = wiki_data.rename(columns={\"logged_in\": \"label\"})\n",
        "# wiki_data = wiki_data.rename(columns={\"comment\": \"text\"})\n",
        "# wiki_data[\"label\"] = wiki_data[\"label\"].map({False: 0, True: 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    61447\n",
            "1     8079\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "0    20422\n",
            "1     2756\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "0    20405\n",
            "1     2755\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "wiki_train = wiki_data[wiki_data['split'] == 'train']\n",
        "wiki_train = wiki_train.drop(columns=[\"split\"])\n",
        "wiki_train\n",
        "print(wiki_train['label'].value_counts())\n",
        "\n",
        "wiki_test = wiki_data[wiki_data['split'] == 'test']\n",
        "wiki_test = wiki_test.drop(columns=[\"split\"])\n",
        "print(wiki_test['label'].value_counts())\n",
        "\n",
        "wiki_dev = wiki_data[wiki_data['split'] == 'dev']\n",
        "wiki_dev = wiki_dev.drop(columns=[\"split\"])\n",
        "print(wiki_dev['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unbalanced dataset for IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def unbalanced(df,p):\n",
        "    df_neg = df[df['label'] == 0]\n",
        "    df_pos = df[df['label'] == 1]\n",
        "    \n",
        "    n_pos = round(len(df_neg)*p/(1-p))\n",
        "    df_pos = df_pos.sample(n=n_pos)\n",
        "    df_unbalanced = pd.concat([df_neg, df_pos])\n",
        "\n",
        "    # Shuffle\n",
        "    df_unbalanced = df_unbalanced.sample(frac=1, random_state=42)\n",
        "    \n",
        "    print(df_unbalanced[\"label\"].value_counts(normalize=True))\n",
        "    print(len(df_unbalanced))\n",
        "    return df_unbalanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    0.899993\n",
            "1    0.100007\n",
            "Name: proportion, dtype: float64\n",
            "13889\n",
            "label\n",
            "0    0.9\n",
            "1    0.1\n",
            "Name: proportion, dtype: float64\n",
            "6880\n",
            "label\n",
            "0    0.899986\n",
            "1    0.100014\n",
            "Name: proportion, dtype: float64\n",
            "7009\n"
          ]
        }
      ],
      "source": [
        "p=0.1\n",
        "\n",
        "IMDB_train_balanced = IMDB_train\n",
        "IMDB_train_unbalanced = unbalanced(IMDB_train, p)\n",
        "\n",
        "IMDB_test_2, IMDB_dev =train_test_split(IMDB_test, test_size=0.5, random_state=42)\n",
        "\n",
        "IMDB_test_balanced = IMDB_test_2\n",
        "IMDB_test_unbalanced = unbalanced(IMDB_test_2, p)\n",
        "\n",
        "IMDB_dev_balanced = IMDB_dev\n",
        "IMDB_dev_unbalanced = unbalanced(IMDB_dev, p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(                                                    text  label\n",
              " 0      I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
              " 1      \"I Am Curious: Yellow\" is a risible and preten...      0\n",
              " 2      If only to avoid making this type of film in t...      0\n",
              " 3      This film was probably inspired by Godard's Ma...      0\n",
              " 4      Oh, brother...after hearing about this ridicul...      0\n",
              " ...                                                  ...    ...\n",
              " 24995  A hit at the time but now better categorised a...      1\n",
              " 24996  I love this movie like no other. Another time ...      1\n",
              " 24997  This film and it's sequel Barry Mckenzie holds...      1\n",
              " 24998  'The Adventures Of Barry McKenzie' started lif...      1\n",
              " 24999  The story centers around Barry McKenzie who mu...      1\n",
              " \n",
              " [25000 rows x 2 columns],\n",
              "                                                     text  label\n",
              " 12204  This movie is a nonsense/spoof comedy, in the ...      0\n",
              " 2655   \"The New hope of Romanian cinema\"...if this is...      0\n",
              " 9592   This movie sucks so bad. Its funny to see what...      0\n",
              " 18228  I think it's incredibly hard to write any kind...      1\n",
              " 18105  That was one of the lines in a trailer about t...      1\n",
              " ...                                                  ...    ...\n",
              " 21575  It's possible to have a good time with this fi...      1\n",
              " 5390   'Illuminata' has expanded the limits of John T...      0\n",
              " 860    Without being really the worst science fiction...      0\n",
              " 15795  A film is beyond all expectations, an excellen...      1\n",
              " 23654  The show itself basically reflects the typical...      1\n",
              " \n",
              " [12500 rows x 2 columns])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_datasets = {\n",
        "    \"train_balanced\": IMDB_train_balanced,\n",
        "    \"train_unbalanced\": IMDB_train_unbalanced,\n",
        "    \"test_balanced\": IMDB_test_balanced,\n",
        "    \"test_unbalanced\": IMDB_test_unbalanced,\n",
        "    \"dev_balanced\": IMDB_dev_balanced,\n",
        "    \"dev_unbalanced\": IMDB_dev_unbalanced\n",
        "}\n",
        "\n",
        "imdb_datasets[\"train_balanced\"],imdb_datasets[\"test_balanced\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Balanced dataset for Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def balanced(df):\n",
        "    df_neg = df[df['label'] == 0]\n",
        "    df_pos = df[df['label'] == 1]\n",
        "    \n",
        "    n_neg = len(df_pos)\n",
        "    df_neg=df_neg.sample(n=n_neg)\n",
        "    df_balanced = pd.concat([df_neg, df_pos])\n",
        "    \n",
        "    # Shuffle\n",
        "    df_balanced = df_balanced.sample(frac=1, random_state=random_seed)\n",
        "    \n",
        "    print(df_balanced[\"label\"].value_counts(normalize=True))\n",
        "    print(len(df_balanced))\n",
        "    return df_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n",
            "16158\n",
            "label\n",
            "1    0.5\n",
            "0    0.5\n",
            "Name: proportion, dtype: float64\n",
            "5512\n",
            "label\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n",
            "5510\n"
          ]
        }
      ],
      "source": [
        "wiki_train_unbalanced = wiki_train\n",
        "wiki_test_unbalanced = wiki_test\n",
        "wiki_dev_unbalanced = wiki_dev\n",
        "\n",
        "wiki_train_balanced = balanced(wiki_train_unbalanced)\n",
        "wiki_test_balanced = balanced(wiki_test_unbalanced)\n",
        "wiki_dev_balanced = balanced(wiki_dev_unbalanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rev_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37675</td>\n",
              "      <td>`-This is not ``creative``.  Those are the dic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44816</td>\n",
              "      <td>`:: the term ``standard model`` is itself less...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49851</td>\n",
              "      <td>True or false, the situation as of March 2002 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>93890</td>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>102817</td>\n",
              "      <td>-Important note for all sysops: There is a bug...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115854</th>\n",
              "      <td>699756185</td>\n",
              "      <td>`The lead itself is original research. Where i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115856</th>\n",
              "      <td>699813325</td>\n",
              "      <td>`::I'm talking about you making unjustified ma...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115859</th>\n",
              "      <td>699848324</td>\n",
              "      <td>`These sources don't exactly exude a sense of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115861</th>\n",
              "      <td>699857133</td>\n",
              "      <td>:The way you're trying to describe it in this ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115863</th>\n",
              "      <td>699897151</td>\n",
              "      <td>Alternate option===Is there perhaps enough new...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69526 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           rev_id                                               text  label\n",
              "0           37675  `-This is not ``creative``.  Those are the dic...      0\n",
              "1           44816  `:: the term ``standard model`` is itself less...      0\n",
              "2           49851  True or false, the situation as of March 2002 ...      0\n",
              "4           93890               This page will need disambiguation.       0\n",
              "5          102817  -Important note for all sysops: There is a bug...      0\n",
              "...           ...                                                ...    ...\n",
              "115854  699756185  `The lead itself is original research. Where i...      0\n",
              "115856  699813325  `::I'm talking about you making unjustified ma...      0\n",
              "115859  699848324  `These sources don't exactly exude a sense of ...      0\n",
              "115861  699857133  :The way you're trying to describe it in this ...      0\n",
              "115863  699897151  Alternate option===Is there perhaps enough new...      0\n",
              "\n",
              "[69526 rows x 3 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_datasets = {\n",
        "    \"train_unbalanced\": wiki_train_unbalanced,\n",
        "    \"test_unbalanced\": wiki_test_unbalanced,\n",
        "    \"dev_unbalanced\": wiki_dev_unbalanced,\n",
        "    \"train_balanced\": wiki_train_balanced,\n",
        "    \"test_balanced\": wiki_test_balanced,\n",
        "    \"dev_balanced\": wiki_dev_balanced,\n",
        "}\n",
        "\n",
        "wiki_train_unbalanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4KtMM1ngpYx"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sf3XvHutgrLn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_and_evaluate_nb(df_train, df_test,n=-1, text_col='text', label_col='label', random_seed=random_seed):\n",
        "\n",
        "    df_train = df_train.dropna(subset=[text_col])\n",
        "    df_test = df_test.dropna(subset=[text_col])\n",
        "    if n > 0:\n",
        "        df_train = df_train.sample(n=n, random_state=random_seed).reset_index(drop=True)\n",
        "    # Extraction des textes et labels\n",
        "    X_train_texts = df_train[text_col]\n",
        "    y_train = df_train[label_col]\n",
        "\n",
        "    X_test_texts = df_test[text_col]\n",
        "    y_test = df_test[label_col]\n",
        "\n",
        "    # Vectorisation du texte avec TF-IDF\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train = vectorizer.fit_transform(X_train_texts)\n",
        "    X_test = vectorizer.transform(X_test_texts)\n",
        "\n",
        "    # Entraînement du modèle Naive Bayes\n",
        "    model_nb = MultinomialNB()\n",
        "    model_nb.fit(X_train, y_train)\n",
        "\n",
        "    # Prédictions et évaluation\n",
        "    preds = model_nb.predict(X_test)\n",
        "    #print(\"=== Évaluation du modèle ===\")\n",
        "    #print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "    #print(classification_report(y_test, preds))\n",
        "\n",
        "    f1_val = f1_score(y_test, preds, average='macro')\n",
        "\n",
        "    return model_nb, f1_val,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toPI236Ru6Wf",
        "outputId": "62820671-7f16-46d1-9305-778fc68b9c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Score F1 ===\n",
            "0.8289532297820281\n"
          ]
        }
      ],
      "source": [
        "model_nb, f1_scor = train_and_evaluate_nb(IMDB_train, IMDB_test)\n",
        "\n",
        "print(\"=== Score F1 ===\")\n",
        "print(f1_scor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_model_performance_by_budget(\n",
        "    datasets_dict,\n",
        "    model_fn,\n",
        "    model_name=\"Naive Bayes\",\n",
        "    labelling_budgets= labelling_budgets,\n",
        "    colors=(\"blue\", \"red\", \"green\")\n",
        "):\n",
        "\n",
        "    f1_score_Balanced = []\n",
        "    f1_score_HalfBalanced = []\n",
        "    f1_score_UnBalanced = []\n",
        "\n",
        "    for budget in labelling_budgets:\n",
        "        # (a) Balanced train + balanced test\n",
        "        _, f1 = model_fn(datasets_dict[\"train_balanced\"], datasets_dict[\"test_balanced\"], budget)\n",
        "        f1_score_Balanced.append(f1)\n",
        "\n",
        "        # (b) Balanced train + unbalanced test\n",
        "        _, f1 = model_fn(datasets_dict[\"train_balanced\"], datasets_dict[\"test_unbalanced\"], budget)\n",
        "        f1_score_HalfBalanced.append(f1)\n",
        "\n",
        "        # (c) Unbalanced train + unbalanced test\n",
        "        _, f1 = model_fn(datasets_dict[\"train_unbalanced\"], datasets_dict[\"test_unbalanced\"], budget)\n",
        "        f1_score_UnBalanced.append(f1)\n",
        "\n",
        "    # --- Plotting ---\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
        "\n",
        "    axes[0].plot(labelling_budgets, f1_score_Balanced, marker='o', color=colors[0], label=model_name)\n",
        "    axes[0].set_title('(a) Balanced train and balanced test')\n",
        "    axes[0].set_xlabel('Labelling budget')\n",
        "    axes[0].set_ylabel('Macro F1 Score')\n",
        "    axes[0].set_ylim(0, 1.0)\n",
        "    axes[0].grid(True)\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].plot(labelling_budgets, f1_score_HalfBalanced, marker='o', color=colors[1], label=model_name)\n",
        "    axes[1].set_title('(b) Balanced train and unbalanced test')\n",
        "    axes[1].set_xlabel('Labelling budget')\n",
        "    axes[1].set_ylim(0, 1.0)\n",
        "    axes[1].grid(True)\n",
        "    axes[1].legend()\n",
        "\n",
        "    axes[2].plot(labelling_budgets, f1_score_UnBalanced, marker='o', color=colors[2], label=model_name)\n",
        "    axes[2].set_title('(c) Unbalanced train and unbalanced test')\n",
        "    axes[2].set_xlabel('Labelling budget')\n",
        "    axes[2].set_ylim(0, 1.0)\n",
        "    axes[2].grid(True)\n",
        "    axes[2].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_model_performance_by_budget(imdb_datasets,train_and_evaluate_nb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplot_model_performance_by_budget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwiki_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_and_evaluate_nb\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mplot_model_performance_by_budget\u001b[39m\u001b[34m(datasets_dict, model_fn, model_name, labelling_budgets, colors)\u001b[39m\n\u001b[32m     16\u001b[39m f1_score_Balanced.append(f1)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# (b) Balanced train + unbalanced test\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m _, f1 = \u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_balanced\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest_unbalanced\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m f1_score_HalfBalanced.append(f1)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# (c) Unbalanced train + unbalanced test\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_and_evaluate_nb\u001b[39m\u001b[34m(df_train, df_test, n, text_col, label_col, random_seed)\u001b[39m\n\u001b[32m     22\u001b[39m vectorizer = TfidfVectorizer()\n\u001b[32m     23\u001b[39m X_train = vectorizer.fit_transform(X_train_texts)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m X_test = \u001b[43mvectorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Entraînement du modèle Naive Bayes\u001b[39;00m\n\u001b[32m     27\u001b[39m model_nb = MultinomialNB()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Scolaire/Columbia/Spring 2025/ML in practice/PROJECT/ML in practice Github/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:2128\u001b[39m, in \u001b[36mTfidfVectorizer.transform\u001b[39m\u001b[34m(self, raw_documents)\u001b[39m\n\u001b[32m   2111\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[32m   2112\u001b[39m \n\u001b[32m   2113\u001b[39m \u001b[33;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2124\u001b[39m \u001b[33;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[32m   2125\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2126\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m, msg=\u001b[33m\"\u001b[39m\u001b[33mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2128\u001b[39m X = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfidf.transform(X, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Scolaire/Columbia/Spring 2025/ML in practice/PROJECT/ML in practice Github/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1421\u001b[39m, in \u001b[36mCountVectorizer.transform\u001b[39m\u001b[34m(self, raw_documents)\u001b[39m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_vocabulary()\n\u001b[32m   1420\u001b[39m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1421\u001b[39m _, X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_vocab\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.binary:\n\u001b[32m   1423\u001b[39m     X.data.fill(\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Scolaire/Columbia/Spring 2025/ML in practice/PROJECT/ML in practice Github/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1272\u001b[39m, in \u001b[36mCountVectorizer._count_vocab\u001b[39m\u001b[34m(self, raw_documents, fixed_vocab)\u001b[39m\n\u001b[32m   1269\u001b[39m             feature_counter[feature_idx] += \u001b[32m1\u001b[39m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m   1271\u001b[39m         \u001b[38;5;66;03m# Ignore out-of-vocabulary items for fixed_vocab=True\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1272\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1274\u001b[39m j_indices.extend(feature_counter.keys())\n\u001b[32m   1275\u001b[39m values.extend(feature_counter.values())\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "plot_model_performance_by_budget(wiki_datasets,train_and_evaluate_nb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6YQyt0wYh5o"
      },
      "source": [
        "# Weak Supervision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wikipedia data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "lDv0pmrFbXLj",
        "outputId": "255dd8ee-7f7e-42f9-cf0f-90a432e38044"
      },
      "outputs": [],
      "source": [
        "from weak_supervision.labeling_functions import get_lfs\n",
        "from snorkel.labeling import PandasLFApplier\n",
        "from snorkel.labeling.model import LabelModel\n",
        "\n",
        "# Data\n",
        "\n",
        "lfs_dict = get_lfs(wiki_keywords_path, wiki_annotations_path)\n",
        "\n",
        "def lf_applier(lf_dict, dftrain, dftest):\n",
        "    lf = list(lf_dict.values())\n",
        "    applier = PandasLFApplier(lf)\n",
        "    L_train = applier.apply(dftrain)\n",
        "    L_test = applier.apply(dftest)\n",
        "    return L_train, L_test\n",
        "\n",
        "def labelmodel(ltrain, ltest, dftest, nepochs, nclass=2, rdseed=random_seed, logfreq=10, tiebreakpolicy='random'):\n",
        "    label_model = LabelModel(nclass, verbose=True)\n",
        "    label_model.fit(ltrain,n_epochs=nepochs, log_freq=logfreq, seed=rdseed)\n",
        "    y_test = dftest['label'].values\n",
        "    y_pred = label_model.predict(L=ltest, tie_break_policy=tiebreakpolicy)\n",
        "    return (y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# L_train, L_test = lf_applier(lfs_dict, wiki_train_unbalanced, wiki_test_unbalanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# f1=[]\n",
        "# for budget in labelling_budgets:\n",
        "#     ytest, ypred = labelmodel(L_train, L_test, wiki_test_unbalanced, nepochs=budget)\n",
        "#     f1val = f1_score(ytest, ypred, average='macro')\n",
        "#     f1.append(f1val)\n",
        "\n",
        "# plt.plot(labelling_budgets, f1)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_model_performance_by_budget_weak_supervision(\n",
        "    datasets_dict,\n",
        "    lf_dict,\n",
        "    applier_fn,\n",
        "    model_fn,\n",
        "    model_name=\"weak_supervision\",\n",
        "    labelling_budgets= labelling_budgets,\n",
        "    colors=(\"blue\", \"red\", \"green\")\n",
        "):\n",
        "\n",
        "    f1_score_Balanced = []\n",
        "    f1_score_HalfBalanced = []\n",
        "    f1_score_UnBalanced = []\n",
        "\n",
        "    ltrain_balanced, ltest_balanced = applier_fn(lf_dict, datasets_dict['train_balanced'], datasets_dict['test_balanced'])\n",
        "    ltrain_halfbalanced, ltest_halfbalanced = applier_fn(lf_dict, datasets_dict['train_balanced'], datasets_dict['test_unbalanced'])\n",
        "    ltrain_unbalanced, ltest_unbalanced = applier_fn(lf_dict, datasets_dict['train_unbalanced'], datasets_dict['test_unbalanced'])\n",
        "\n",
        "    f1s = lambda ytest, ypred: f1_score(ytest, ypred, average='macro')\n",
        "\n",
        "    for budget in labelling_budgets:\n",
        "        # (a) Balanced train + balanced test\n",
        "        ytest_balanced, ypred_balanced = model_fn(ltrain_balanced, ltest_balanced, datasets_dict[\"test_balanced\"], nepochs=budget)\n",
        "        f1_score_Balanced.append(f1s(ytest_balanced, ypred_balanced))\n",
        "\n",
        "        # (b) Balanced train + unbalanced test\n",
        "        ytest_halfbalanced, ypred_halfbalanced = model_fn(ltrain_halfbalanced, ltest_halfbalanced, datasets_dict[\"test_unbalanced\"], nepochs=budget)\n",
        "        f1_score_HalfBalanced.append(f1s(ytest_halfbalanced, ypred_halfbalanced))\n",
        "\n",
        "        # (c) Unbalanced train + unbalanced test\n",
        "        ytest_unbalanced, ypred_unbalanced = model_fn(ltrain_unbalanced, ltest_unbalanced, datasets_dict[\"test_unbalanced\"], nepochs=budget)\n",
        "        f1_score_UnBalanced.append(f1s(ytest_unbalanced, ypred_unbalanced))\n",
        "\n",
        "    # --- Plotting ---\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
        "\n",
        "    axes[0].plot(labelling_budgets, f1_score_Balanced, marker='o', color=colors[0], label=model_name)\n",
        "    axes[0].set_title('(a) Balanced train and balanced test')\n",
        "    axes[0].set_xlabel('Labelling budget')\n",
        "    axes[0].set_ylabel('Macro F1 Score')\n",
        "    axes[0].set_ylim(0, 1.0)\n",
        "    axes[0].grid(True)\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].plot(labelling_budgets, f1_score_HalfBalanced, marker='o', color=colors[1], label=model_name)\n",
        "    axes[1].set_title('(b) Balanced train and unbalanced test')\n",
        "    axes[1].set_xlabel('Labelling budget')\n",
        "    axes[1].set_ylim(0, 1.0)\n",
        "    axes[1].grid(True)\n",
        "    axes[1].legend()\n",
        "\n",
        "    axes[2].plot(labelling_budgets, f1_score_UnBalanced, marker='o', color=colors[2], label=model_name)\n",
        "    axes[2].set_title('(c) Unbalanced train and unbalanced test')\n",
        "    axes[2].set_xlabel('Labelling budget')\n",
        "    axes[2].set_ylim(0, 1.0)\n",
        "    axes[2].grid(True)\n",
        "    axes[2].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def make_100row_versions(datasets_dict):\n",
        "#     \"\"\"Return a dict with 100-row versions of each dataset split.\"\"\"\n",
        "#     small_versions = {}\n",
        "#     for key, df in datasets_dict.items():\n",
        "#         small_versions[key] = df.sample(n=1000, random_state=42).reset_index(drop=True)\n",
        "#     return small_versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot_model_performance_by_budget_weak_supervision(\n",
        "#     make_100row_versions(wiki_datasets),\n",
        "#     lfs_dict,\n",
        "#     lf_applier,\n",
        "#     labelmodel,\n",
        "#     'weak_supervision_wiki'\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from weak_supervision.labeling_functions import get_lfs_imdb\n",
        "\n",
        "# lfs_dict_imdb = get_lfs_imdb()\n",
        "\n",
        "# plot_model_performance_by_budget_weak_supervision(\n",
        "#     make_100row_versions(imdb_datasets),\n",
        "#     lfs_dict_imdb,\n",
        "#     lf_applier,\n",
        "#     labelmodel,\n",
        "#     'weak_supervision_imdb'\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_model_performance_by_budget_weak_supervision(\n",
        "    wiki_datasets,\n",
        "    lfs_dict,\n",
        "    lf_applier,\n",
        "    labelmodel,\n",
        "    'weak_supervision_wiki'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IMDB data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from weak_supervision.labeling_functions import get_lfs_imdb\n",
        "\n",
        "lfs_dict_imdb = get_lfs_imdb()\n",
        "\n",
        "plot_model_performance_by_budget_weak_supervision(\n",
        "    imdb_datasets,\n",
        "    lfs_dict_imdb,\n",
        "    lf_applier,\n",
        "    labelmodel,\n",
        "    'weak_supervision_imdb'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Ag7_fZYv7y"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=2)\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "dataset_train = Dataset.from_pandas(IMDB_train_balanced[['text', 'label']])\n",
        "dataset_test = Dataset.from_pandas(IMDB_test_balanced[['text', 'label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\",   max_length=512)\n",
        "\n",
        "tokenized_train = dataset_train.map(tokenize_function, batched=True)\n",
        "tokenized_test = dataset_test.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtUKmpYyY5Dp"
      },
      "source": [
        "# Prompt Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CioFke6Y9bE"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1\",\n",
        "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
